# -*- coding: utf-8 -*-
"""DNN_Smile-Detector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BXO--aacW1QlJEOrMi71BYpU2ne2v6rS

#**Smile Detector using Deep Neural Network**

Smile Detector Project using Deep Neural Network is a simple implementation of DNN on Emoji faces of happy and sad. We will read the emojis from images and train them on our DNN. Later we use the trained model to predict whether the face image provided is happy or sad. For this we are going to use 10 happy faces and 10 sad faces for training, and one from each category for testing.

The steps followed in this mini-project are:
1. Importing the necessary packages
2. Reading the images from directory and converting them into Features and Labels.
3. Applying Min-Max Normalization on Features
4. Creating a DNN Model for training and testing the data
5. Compiling the Model
6. Training the Model
7. Evaluating the Model on Test Data
8. Making predictions using Test Data

Let's implement the above steps one-by-one.

###**1. Importing the necessary packages**
"""

import os
import numpy as np
from PIL import Image
from keras.models import Sequential
from keras.layers.core import Dense
from keras.optimizers import Adam

"""###**2. Reading the images from directory and converting them into Features and Labels.**

The images are in `training_data` folder. So we have to read the images using PIL, and convert them into pixel intensities.

The output has 2 classes, so the labels will have 2 values
1. First Class: (1, 0)
2. Second Class: (0, 1)
"""

# Function to convert images of a folder into pixel intensities and labels
def images_to_pixel_intensities(directory):
  # Create a list for holding pixel intensities which are our labels primarily
  pixel_intensities = []

  # Create a list for holding the labels
  labels = []

  # Reading the images from folder and creating features and labels
  files = os.listdir(directory)
  for file in files:
    # Creating the features
    image = Image.open(directory + file).convert("1")
    pixel_intensities.append(list(image.getdata()))

    # Creating labels from file names
    if (file[:5] == "happy"):
      labels.append([1, 0])
    elif (file[:3] == "sad"):
      labels.append([0, 1])

  # Convert the features and labels into numpy array 
  pixel_intensities = np.array(pixel_intensities)
  labels = np.array(labels)
  return pixel_intensities, labels

# Defining the directory for training data
directory = "training_data/"

# Convert the images to pixel_intensities and labels
pixel_intensities, labels = images_to_pixel_intensities(directory)

# Check the dimensions
print(pixel_intensities.shape)
print(labels.shape)

"""We have a total of 20 images (10 - Happy, 10 - Sad).

###**3. Applying Min-Max Normalization on Features**
"""

pixel_intensities = pixel_intensities / 255.0

"""###**4. Creating a DNN Model**"""

model = Sequential()

# Now add layers to the Sequential model
# We add 2 Hidden layers with "ReLU" activation function

# First hidden layer works as the input layer
model.add(Dense(1024, input_dim = 1024, activation = 'relu')) # Input Layer

model.add(Dense(512, activation = 'relu')) # Hidden Layer 1
model.add(Dense(128, activation = 'relu')) # Hidden Layer 2

# Now add output layer with 1 output value and "Sigmoid" as activation function
model.add(Dense(2, activation = 'sigmoid')) # Output Layer

"""###**Compile the Model**

We can define the loss function as MSE or Negative Log Likelihood and Optimizer will find the right adjustments for the weights: SGD, Adagrad, ADAM...
"""

model.compile(loss = 'categorical_crossentropy',
              optimizer = Adam(lr = 0.005),
              metrics = ['accuracy'])

"""###**Train the Model**"""

model.fit(pixel_intensities, 
          labels, 
          epochs = 1000, 
          batch_size = 20, 
          verbose = 2)

"""###**Evaluating the Model**

Evaluate the model using the test data to know the accuracy on test data.
"""

test_dir = "test_data/"
test_features, test_labels = images_to_pixel_intensities(test_dir)
results = model.evaluate(test_features, test_labels, use_multiprocessing = True)
print("Training is finished. The loss and accuracy values are: ")
print(results)

"""###**Making Predictions**

Now make a function to predict the mood of given emoji face image.
"""

def predict_mood(new):
  new = new / 255.0
  predict = model.predict(new.reshape(-1, 1024))
  cls = np.argmax(predict)
  classes = ['Happy Face', 'Sad Face']
  return classes[cls]

input_image = test_features[0]
predicted = predict_mood(input_image)
print(f"Input array is: {input_image}")
print(f"The predicted class is: {predicted}")